{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtTlA1fCMpup"
      },
      "source": [
        "# Sieci neuronowe z wykorzystaniem Kerasa (1)\n",
        "## Głębokie uczenie\n",
        "\n",
        "# 1. Podstawy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9SBICeSNUfy"
      },
      "source": [
        "**Zanim przejdziemy do bardziej zaawansowanego przykładu, zapoznamy się z Tensorflow i Keras. Przyjrzymy się pierwszemu konkretnemu przykładowi sieci neuronowej, która wykorzystuje bibliotekę Python Keras do nauki klasyfikacji odręcznie pisanych cyfr.**\n",
        "\n",
        "Problemem, który staramy się rozwiązać, jest klasyfikacja obrazów pogrubiony tekstodręcznych cyfr w skali szarości (28 pikseli na 28 pikseli) do 10 kategorii (od 0 do 9). Zbiór danych, którego użyjemy to MNIST. Jest to zestaw 60 000 obrazów treningowych plus 10 000 obrazów testowych, zebranych przez National Institute of Standards and Technology (NIST w MNIST) w latach 80-tych.\n",
        "\n",
        "Możesz myśleć o \"rozwiązywaniu\" MNIST jako o \"Hello World\" głębokiego uczenia się - to jest to, co robisz, aby sprawdzić, czy twoje algorytmy działają zgodnie z oczekiwaniami.\n",
        "\n",
        "Po pierwsze, zaimportujemy Keras (w oparciu o wersję Python/Tensorflow):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c0Q_VZGlNT1j"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_jY1oOO5YY"
      },
      "source": [
        "Jeśli korzystasz z najnowszej wersji Tensorflow (keras jest już dołączony), dodaj dodatkową funkcjonalność za pomocą:\n",
        "\n",
        "```\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import XXX\n",
        "```\n",
        "\n",
        "Zbiór danych MNIST jest wstępnie załadowany do Keras w postaci zestawu czterech tablic Numpy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sSYMk1IQPUwY"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS2FZz-VPcUv"
      },
      "source": [
        "**Zadanie 1**\n",
        "\n",
        "*   Sprawdź liczbę przykładów treningowych i testowych."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_images.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   Ile mamy etykiet?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_labels.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*   Sprawdź rozmiar obrazu i wykreśl kilka przykładów\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_images.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "kilka = 3\n",
        "for i in range(kilka):\n",
        "    fig, ax = plt.subplots(figsize=(1, 1), facecolor='black')\n",
        "    ax.imshow(train_images[i], cmap='gray', vmin=0, vmax=255)\n",
        "    ax.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyvLX0LTPvFr"
      },
      "source": [
        "**Przepływ pracy DNN**\n",
        "1. Tworzenie architektury sieci neuronowej.\n",
        "2. Trenuj naszą sieć neuronową za pomocą danych treningowych, train_images i train_labels. Następnie sieć nauczy się kojarzyć obrazy i etykiety.\n",
        "3. Sieć wygeneruje prognozy dla test_images i sprawdzimy, czy te prognozy są zgodne z etykietami z test_labels.  \n",
        "  \n",
        "**Architektura DNN**\n",
        "1. Nasza sieć będzie składać się z sekwencji dwóch warstw `Dense`, które są gęsto połączonymi (zwanymi również \"w pełni połączonymi\") warstwami neuronowymi.\n",
        "2. Druga (i ostatnia) warstwa to 10-kierunkowa warstwa \"softmax\", co oznacza, że zwróci ona tablicę 10 wyników prawdopodobieństwa (sumujących się do 1). Każdy wynik będzie prawdopodobieństwem, że bieżący obraz cyfry należy do jednej z naszych 10 klas cyfr.\n",
        "\n",
        "Trening DNN\n",
        "Aby nasza sieć była gotowa do treningu, musimy wybrać jeszcze trzy elementy w ramach etapu \"kompilacji\":\n",
        "1. **Funkcja straty**: Jest to sposób, w jaki sieć będzie w stanie zmierzyć, jak dobrze radzi sobie z danymi treningowymi, a tym samym, w jaki sposób będzie w stanie iść we właściwym kierunku.\n",
        "2. **Optymalizator**: jest to mechanizm, za pomocą którego sieć będzie się aktualizować w oparciu o dane, które widzi i funkcję strat.\n",
        "3. **Metryki**: do monitorowania podczas szkolenia i testowania. Tutaj będziemy dbać tylko o `dokładność` (ułamek obrazów, które zostały poprawnie sklasyfikowane).\n",
        "\n",
        "Dzisiaj, podczas naszych 3 przykładów, będziemy używać tylko klasy Sequential. Podczas naszych następnych spotkań przedstawię funkcjonalne API, w którym będziemy mogli manipulować tensorami danych przetwarzanymi przez model i stosować warstwy do tych tensorów tak, jakby były funkcjami.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPWO4vhYRcUQ"
      },
      "source": [
        "**Architektura sieci**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "network = models.Sequential()\n",
        "network.add(layers.Input(shape=(train_images.shape[1]**2,)))\n",
        "network.add(layers.Dense(512, activation='relu'))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xICk2gK6RqBx"
      },
      "source": [
        "**Trening sieci**\n",
        "\n",
        "Po zdefiniowaniu architektury modelu proces uczenia można skonfigurować na etapie kompilacji. Określamy: optymalizator, funkcję straty i metryki."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-dIvwKkiRvoa"
      },
      "outputs": [],
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pp7U8xlR1vn"
      },
      "source": [
        "**Przygotowanie danych**\n",
        "\n",
        "Przed treningiem wstępnie przetworzymy nasze dane, przekształcając je w kształt oczekiwany przez sieć i skalując tak, aby wszystkie wartości mieściły się w przedziale [0, 1].\n",
        "\n",
        "Nasze obrazy treningowe są przechowywane w tablicy o kształcie (60000, 28, 28) typu uint8 z wartościami w przedziale [0, 255].\n",
        "\n",
        "Przekształć je w tablicę float32 typu shape (60000, 28 * 28) z wartościami od 0 do 1.\n",
        "Niezbędne funkcje: `reshape` i `astype`.\n",
        "\n",
        "**Wykonaj to zarówno dla przykładów treningowych, jak i testowych.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_images_reshaped = train_images.reshape((60_000, 28*28)).astype(np.float32)/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_images_reshaped = test_images.reshape((10_000, 28*28)).astype(np.float32)/255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75qoxtmBSTdO"
      },
      "source": [
        "Ponieważ używamy funkcji straty `categorical_crossentropy`, musimy przekonwertować format danych:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1izRkD_LSaJY"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCvN2vJASgWX"
      },
      "source": [
        "**Dopasowanie modelu**\n",
        "\n",
        "Aby wytrenować naszą sieć, wywołujemy metodę dopasowania sieci z parametrami epochs i batch_size. Ustawmy epochs na 5, a batch_size na 128."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.4333\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9643 - loss: 0.1204\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0739\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0512\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9891 - loss: 0.0365\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x109a530d0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TODO: naprawic\n",
        "network.fit(train_images_reshaped, train_labels, batch_size=128, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p_Lx8NzSvWo"
      },
      "source": [
        "**Ocena sieci/Ewaluacja**\n",
        "\n",
        "Podczas treningu wyświetlane są dwie wielkości: \"strata\" sieci na danych szkoleniowych oraz dokładność sieci na danych szkoleniowych.\n",
        "Szybko osiągamy dokładność 0,989 (tj. 98,9%) na danych treningowych.\n",
        "\n",
        "Teraz sprawdźmy, czy nasz model działa dobrze również na zestawie testowym:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LRb3leqhS7l2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.9754 - loss: 0.0747\n",
            "test_acc: 0.979200005531311\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = network.evaluate(test_images_reshaped, test_labels)\n",
        "\n",
        "print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3jkpKtJTBWW"
      },
      "source": [
        "Dokładność naszego zestawu testowego okazuje się wynosić 97,8% - to znacznie mniej niż dokładność zestawu treningowego.\n",
        "Ta różnica między dokładnością treningu a dokładnością testu jest przykładem \"**nadmiernego dopasowania**\", czyli faktu, że modele uczenia maszynowego mają tendencję do osiągania gorszych wyników na nowych danych niż na danych treningowych.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning_pieta",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
